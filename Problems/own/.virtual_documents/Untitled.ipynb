import pandas as pd
import scipy.stats as stats
import seaborn as sns


data = pd.read_csv("./book_reviews.csv")


data.head()


data.price.mean()


def bootstrap_ttest(orig, data: pd.Series, pop_mean, frac = 0.1, boos = 500) -> list:
    
    print("BOOTSTRAPING T TEST".center(55))
    print("-"*55, "\n")
    pop_mean = data.mean()
    info_str = ""
    lst_t = list()
    lst_p = list()
    lst_r = list()
    lst_sm = list()
    lst_sd = list()
    print("No. of BootStraps : ", boos)
    print("Population size   : ", data.count())
    print("Population Mean   : ", round(pop_mean, 5))
    print("Sample Fraction   : ", int(frac*100), "%")
    print("Sample size       : ", int(data.count()*frac))
    print()
    
    for i in range(boos):
        sam = data.sample(frac=frac)
        t_stat, p_val = stats.mannwhitneyu(sam, data)
        lst_sm.append(sam.mean())
        lst_sd.append(sam.std())
        lst_t.append(t_stat)
        lst_p.append(p_val)
        # print(stats.shapiro(sam))
    info_str = info_str + "\033[1m" + "Sam Mean".rjust(10) + "Sam Std".rjust(9) + "T Val".rjust(9) + "   "  +"P Value".rjust(8) + "Result".rjust(9) + "\033[0m"
    for i in range(boos):
        result = "Fail" if lst_p[i] <= 0.05 else "Pass"
        lst_r.append(result)
        info_str = info_str + str( f"{lst_sm[i]:3.4f}").rjust(10) + str(f"{lst_sd[i]:3.4f}").rjust(10) + str(f"{lst_t[i]:3.4f}").rjust(10) + "   " + str(f"{lst_p[i]:3.4f}").rjust(6) + f"{result}".rjust(8)    
        info_str = info_str + "\n" + "\033[1m" + "Result counts" + "\033[0m"
    print(stats.mannwhitneyu(lst_sm, orig))
    print(pd.value_counts(lst_r))
    
    return([list(lst_t), list(lst_p), list(lst_r)])


t_vals, p_vals, r_vals = bootstrap_ttest(orig = data.price, data = data.sample(frac=0.10).price, pop_mean=31.287030000000005, frac=0.1, boos=500)








import numpy as np


Ni = np.array([500, 400, 300, 200, 100])
ymean = np.array([80, 100, 120, 150, 200])
Si = np.array([5.25, 10.75, 15.5, 20.5, 25])
Ci = np.array([100, 100, 150, 175, 200])
C0 = 10000
C = 50000
N = sum(Ni)
Wi = Ni/N


Ni


Ci





Ni*Ci/N


sum(Ni*Ci/N)


n = np.floor(40000/sum(Ni*Ci/N), )
n = int(n)
n


ni = n*Ni/N # sample sizes for proportional allocation
ni


(Wi[1]**2) * ( (1/ni[1]) - (1/Ni[1]) ) * (Si[1]**2)


var = np.sum([Wi[i]**2*((1/ni[i]) - (1/Ni[i]))*Si[i]**2 for i in range(len(Ni))])
var # Variance





# for neymann allocation
Ni*Si


sum(Ni*Si)


Ni*Si*Ci


sum(Ni*Si*Ci)


n = 40000*sum(Ni*Si) / (sum(Ni*Si*Ci))
n


ni = n*Ni*Si/sum(Ni*Si) # sample sizes for neymann allocation
ni


var = np.sum([Wi[i]**2*((1/ni[i]) - (1/Ni[i]))*Si[i]**2 for i in range(len(Ni))])
var # Variance





# for optimal allocation
Ni*Si


Ni*Si/np.sqrt(Ci)


sum(Ni*Si/np.sqrt(Ci))


Ni*Si*np.sqrt(Ci)


sum(Ni*Si*np.sqrt(Ci))


n = 40000 * sum(Ni*Si/np.sqrt(Ci)) / sum(Ni*Si*np.sqrt(Ci))
n


ni = ( n * Ni * Si / np.sqrt(Ci) ) / sum(Ni*Si/np.sqrt(Ci)) # sample sizes for optimum allocation
ni


var = np.sum([Wi[i]**2*((1/ni[i]) - (1/Ni[i]))*Si[i]**2 for i in range(len(Ni))])
var # Variance





Ni = [1411, 4705, 2558, 14997]
N = sum(Ni)
n1 = [43,84,98,0,10,44,0,124,13,0]
n2 = [50, 147, 62, 87, 84, 158, 170, 104, 56, 160]
n3 = [228, 262, 110, 232, 139, 178, 334, 0, 63, 220]
n4 = [17, 34, 25, 34, 36, 0, 25, 7, 15, 31]


ymean = np.array([np.mean(n1), np.mean(n2), np.mean(n3), np.mean(n4)])
ymean


sub_pop_tot = Ni*ymean
sub_pop_tot


Ni*ymean**2


ni = np.array([10]*4)


pop_tot = sum(sub_pop_tot)
pop_tot


si = np.array([np.std(i, ddof=1) for i in [n1, n2, n3, n4]])


var_st = sum(np.sqrt(Ni*(Ni - ni)*si**2 / ni ))
var_st


var_srs = (1/50 + 1/N) * N * (np.sum(Ni*si**2)- np.sum(Ni*si**2/ni) + np.sum() - np.sum(Ni*ymean)**2)
var_srs



